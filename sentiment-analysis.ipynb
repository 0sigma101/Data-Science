{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"The dataset is [here](https://github.com/google-research/google-research/tree/master/goemotions)","metadata":{"id":"0XPxuM_zMvzD"}},{"cell_type":"code","source":"'''from google.colab import auth\n\nauth.authenticate_user()'''","metadata":{"id":"a5Y5r-BCUhgj","execution":{"iopub.status.busy":"2023-06-16T21:10:48.521571Z","iopub.execute_input":"2023-06-16T21:10:48.522524Z","iopub.status.idle":"2023-06-16T21:10:48.530308Z","shell.execute_reply.started":"2023-06-16T21:10:48.522478Z","shell.execute_reply":"2023-06-16T21:10:48.528963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''!curl https://sdk.cloud.google.com | bash'''","metadata":{"id":"6v0cOFruU8MC","outputId":"b4ce9776-d780-4033-d585-3a6d06100a9a","execution":{"iopub.status.busy":"2023-06-16T21:10:48.537186Z","iopub.execute_input":"2023-06-16T21:10:48.537668Z","iopub.status.idle":"2023-06-16T21:10:48.545930Z","shell.execute_reply.started":"2023-06-16T21:10:48.537607Z","shell.execute_reply":"2023-06-16T21:10:48.544828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!gcloud init","metadata":{"id":"WEjVqM6lVE6a","outputId":"4b8cbf24-de95-49a6-ce78-b15499e1626f","execution":{"iopub.status.busy":"2023-06-16T21:10:48.551815Z","iopub.execute_input":"2023-06-16T21:10:48.552524Z","iopub.status.idle":"2023-06-16T21:10:48.560105Z","shell.execute_reply.started":"2023-06-16T21:10:48.552474Z","shell.execute_reply":"2023-06-16T21:10:48.559257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gsutil cp -r gs://gresearch/goemotions/data/full_dataset/ .","metadata":{"id":"5G0jPlbQVwci","outputId":"acc0d9ba-f6cd-4cb2-f78f-541471868958","execution":{"iopub.status.busy":"2023-06-16T21:10:48.568799Z","iopub.execute_input":"2023-06-16T21:10:48.569233Z","iopub.status.idle":"2023-06-16T21:10:53.013811Z","shell.execute_reply.started":"2023-06-16T21:10:48.569199Z","shell.execute_reply":"2023-06-16T21:10:53.012025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nimport string\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\n\nfrom sklearn.metrics import accuracy_score","metadata":{"id":"SuSRywTAMnvC","execution":{"iopub.status.busy":"2023-06-16T21:10:53.016758Z","iopub.execute_input":"2023-06-16T21:10:53.017247Z","iopub.status.idle":"2023-06-16T21:10:53.025032Z","shell.execute_reply.started":"2023-06-16T21:10:53.017190Z","shell.execute_reply":"2023-06-16T21:10:53.024061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Will use goemotion1, goemotion2 to train and goemotion3 to test","metadata":{"id":"WLTadPXUWV86"}},{"cell_type":"code","source":"df1 = pd.read_csv(\"/kaggle/working/full_dataset/goemotions_1.csv\")\ndf2 = pd.read_csv(\"/kaggle/working/full_dataset/goemotions_2.csv\")\ndf3 = pd.read_csv(\"/kaggle/working/full_dataset/goemotions_3.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-06-16T21:10:53.026253Z","iopub.execute_input":"2023-06-16T21:10:53.027269Z","iopub.status.idle":"2023-06-16T21:10:54.740150Z","shell.execute_reply.started":"2023-06-16T21:10:53.027231Z","shell.execute_reply":"2023-06-16T21:10:54.738927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = df1[df1['example_very_unclear'] == False]\ndf2 = df2[df2['example_very_unclear'] == False]\ndf3 = df3[df3['example_very_unclear'] == False]","metadata":{"execution":{"iopub.status.busy":"2023-06-16T21:10:54.743846Z","iopub.execute_input":"2023-06-16T21:10:54.744232Z","iopub.status.idle":"2023-06-16T21:10:54.808455Z","shell.execute_reply.started":"2023-06-16T21:10:54.744199Z","shell.execute_reply":"2023-06-16T21:10:54.807195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-16T21:10:54.810356Z","iopub.execute_input":"2023-06-16T21:10:54.810795Z","iopub.status.idle":"2023-06-16T21:10:54.819058Z","shell.execute_reply.started":"2023-06-16T21:10:54.810759Z","shell.execute_reply":"2023-06-16T21:10:54.817613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.concat([df1,df2,df3], axis=0)","metadata":{"id":"pi2XPUjqPyCU","execution":{"iopub.status.busy":"2023-06-16T21:10:54.821313Z","iopub.execute_input":"2023-06-16T21:10:54.821746Z","iopub.status.idle":"2023-06-16T21:10:54.945230Z","shell.execute_reply.started":"2023-06-16T21:10:54.821709Z","shell.execute_reply":"2023-06-16T21:10:54.944199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.columns","metadata":{"id":"-E088HjOP3BD","outputId":"e2f3a68b-6a5c-45d4-b854-7d60e2222355","execution":{"iopub.status.busy":"2023-06-16T21:10:54.946610Z","iopub.execute_input":"2023-06-16T21:10:54.947006Z","iopub.status.idle":"2023-06-16T21:10:54.955694Z","shell.execute_reply.started":"2023-06-16T21:10:54.946973Z","shell.execute_reply":"2023-06-16T21:10:54.954379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"id":"sZRBLIhCWkc7","outputId":"9708ba28-1c5f-4d3f-daf7-05d3b16f2e25","execution":{"iopub.status.busy":"2023-06-16T21:10:54.956921Z","iopub.execute_input":"2023-06-16T21:10:54.957303Z","iopub.status.idle":"2023-06-16T21:10:55.395998Z","shell.execute_reply.started":"2023-06-16T21:10:54.957272Z","shell.execute_reply":"2023-06-16T21:10:55.394445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df_train.drop(['id','author','subreddit','link_id','parent_id','created_utc','rater_id','example_very_unclear'],axis = 1)","metadata":{"id":"G56emVP6WsaS","execution":{"iopub.status.busy":"2023-06-16T21:10:55.397375Z","iopub.execute_input":"2023-06-16T21:10:55.398017Z","iopub.status.idle":"2023-06-16T21:10:55.436992Z","shell.execute_reply.started":"2023-06-16T21:10:55.397982Z","shell.execute_reply":"2023-06-16T21:10:55.435432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"id":"oXjMCZt3X7uq","outputId":"446b3dc5-79ad-4845-c289-57c4d7b0b49f","execution":{"iopub.status.busy":"2023-06-16T21:10:55.441861Z","iopub.execute_input":"2023-06-16T21:10:55.442292Z","iopub.status.idle":"2023-06-16T21:10:55.540044Z","shell.execute_reply.started":"2023-06-16T21:10:55.442255Z","shell.execute_reply":"2023-06-16T21:10:55.538634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download NLTK resources (run once)\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.data.path.append(\"/root/nltk_data\")\nnltk.download('wordnet')","metadata":{"id":"zIBt8VRNOgWq","outputId":"4fcacd1c-29ff-4429-8503-039be1ff6123","execution":{"iopub.status.busy":"2023-06-16T21:10:55.542062Z","iopub.execute_input":"2023-06-16T21:10:55.542523Z","iopub.status.idle":"2023-06-16T21:10:55.557710Z","shell.execute_reply.started":"2023-06-16T21:10:55.542481Z","shell.execute_reply":"2023-06-16T21:10:55.556129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"execution":{"iopub.status.busy":"2023-06-16T21:10:55.559507Z","iopub.execute_input":"2023-06-16T21:10:55.560213Z","iopub.status.idle":"2023-06-16T21:10:59.828594Z","shell.execute_reply.started":"2023-06-16T21:10:55.560157Z","shell.execute_reply":"2023-06-16T21:10:59.827086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_byte_data(value):\n    if isinstance(value, bytes):\n        value = value.decode('utf-8', errors='ignore')\n        removelist = \"\"\n        value = re.sub('<.*?>', '', value)  # remove HTML tags\n        value = re.sub('https://.*', '', value)  # remove URLs\n        value = re.sub(r'[^a-zA-Z0-9' + removelist + ']', ' ', result)  # remove non-alphanumeric characters\n        value = result.lower()\n    else:\n        return str(value)\n        removelist = \"\"\n        value = re.sub('<.*?>', '', value)  # remove HTML tags\n        value = re.sub('https://.*', '', value)  # remove URLs\n        value = re.sub(r'[^a-zA-Z0-9' + removelist + ']', ' ', value)  # remove non-alphanumeric characters\n        value = result.lower()\n\ndf['text'] = df['text'].apply(lambda x: remove_byte_data(x))","metadata":{"id":"3KzRCJOJdUuM","execution":{"iopub.status.busy":"2023-06-16T21:10:59.830455Z","iopub.execute_input":"2023-06-16T21:10:59.830913Z","iopub.status.idle":"2023-06-16T21:11:00.006195Z","shell.execute_reply.started":"2023-06-16T21:10:59.830868Z","shell.execute_reply":"2023-06-16T21:11:00.003715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_text(text):\n    text = str(text)\n    # Tokenization\n    tokens = word_tokenize(text)\n\n    # Remove punctuation\n    tokens = [token for token in tokens if token not in string.punctuation]\n\n    # Convert to lowercase\n    tokens = [token.lower() for token in tokens]\n\n    # Remove stopwords\n    stop_words = set(stopwords.words('english'))\n    tokens = [token for token in tokens if token not in stop_words]\n\n    # Lemmatization\n    lemmatizer = WordNetLemmatizer()\n    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n\n    # Join tokens back into a string\n    preprocessed_text = ' '.join(tokens)\n\n    return preprocessed_text\n\n# Example usage\ndf['text'] = df['text'].apply(lambda x: preprocess_text(x))","metadata":{"id":"GBiTxO3JNSDu","execution":{"iopub.status.busy":"2023-06-16T21:11:00.009162Z","iopub.execute_input":"2023-06-16T21:11:00.010276Z","iopub.status.idle":"2023-06-16T21:12:54.709027Z","shell.execute_reply.started":"2023-06-16T21:11:00.010217Z","shell.execute_reply":"2023-06-16T21:12:54.707603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create TF-IDF vectorizer\nvectorizer = CountVectorizer(max_features = 5500)\n\n# Fit the vectorizer toCountVectorizerpreprocessed text data\nX = vectorizer.fit_transform(df['text'])\n\n# Get the feature names (words) as a list\nfeature_names = vectorizer.get_feature_names_out()\n\n# Print the feature names (optional)\nprint(feature_names)\n\n# Access the feature vectors\nfeature_vectors = X.toarray()\n\n# Print the shape of the feature vectors (optional)\nprint(feature_vectors.shape)","metadata":{"id":"UwmAE5tDNzI6","outputId":"799a9434-9948-46e5-c770-df1399caa9d9","execution":{"iopub.status.busy":"2023-06-16T21:29:18.877212Z","iopub.execute_input":"2023-06-16T21:29:18.877709Z","iopub.status.idle":"2023-06-16T21:29:26.813655Z","shell.execute_reply.started":"2023-06-16T21:29:18.877676Z","shell.execute_reply":"2023-06-16T21:29:26.811983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(feature_vectors, df[['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']], test_size=0.2, random_state=42)\n\n# Create a Naive Bayes classifier\nnb_classifier = MultinomialNB(alpha=1)\n\n#making it 1D\ny_train = np.argmax(y_train.values, axis=1)\ny_test = np.argmax(y_test.values, axis=1)\n\n# Train the classifier\nnb_classifier.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = nb_classifier.predict(X_test)\n\n# Calculate the accuracy of the classifier\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)","metadata":{"id":"1myoX1ElPF1a","execution":{"iopub.status.busy":"2023-06-16T21:29:26.816002Z","iopub.execute_input":"2023-06-16T21:29:26.816521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_rows= np.unique(y_pred, axis=0)\nunique_rows","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}